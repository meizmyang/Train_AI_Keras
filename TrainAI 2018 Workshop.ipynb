{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Deep Learning \n",
    "May 9 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron - Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0884 - acc: 0.9115 - val_loss: 0.0665 - val_acc: 0.9330\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0650 - acc: 0.9349 - val_loss: 0.0504 - val_acc: 0.9495\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0540 - acc: 0.9458 - val_loss: 0.0429 - val_acc: 0.9569\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0497 - acc: 0.9501 - val_loss: 0.0464 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0437 - acc: 0.9562 - val_loss: 0.0462 - val_acc: 0.9537\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0411 - acc: 0.9588 - val_loss: 0.0355 - val_acc: 0.9644\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0400 - acc: 0.9598 - val_loss: 0.0354 - val_acc: 0.9646\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.0443 - acc: 0.9556 - val_loss: 0.0547 - val_acc: 0.9451\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0400 - acc: 0.9599 - val_loss: 0.0356 - val_acc: 0.9643\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0365 - acc: 0.9634 - val_loss: 0.0331 - val_acc: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbef1dcc18>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "is_five_train = y_train == 5\n",
    "is_five_test = y_test == 5\n",
    "labels = [\"Not Five\", \"Is Five\"]\n",
    "\n",
    "img_width = X_train.shape[1] #28\n",
    "img_height = X_train.shape[2] #28\n",
    "\n",
    "# create model\n",
    "## The Sequential model is a linear stack of layers.\n",
    "model=Sequential()\n",
    "## You can also simply add layers via the .add() method\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "## Before training a model, you need to configure the learning process, \n",
    "## which is done via the compile method. \n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, is_five_train, epochs=10, validation_data=(X_test, is_five_test),\n",
    "                    callbacks=[WandbCallback(validation_data=X_test, labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 785       \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0331063477157822, 0.9668]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, is_five_test, verbose=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 423.1028 - acc: 0.1108 - val_loss: 27.1033 - val_acc: 0.1011\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 9.2968 - acc: 0.1468 - val_loss: 1.7208 - val_acc: 0.2314\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 4.6359 - acc: 0.1728 - val_loss: 5.1896 - val_acc: 0.1281\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 6.1310 - acc: 0.1551 - val_loss: 4.8008 - val_acc: 0.1289\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 6.8022 - acc: 0.1556 - val_loss: 9.6581 - val_acc: 0.1540\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 6.8576 - acc: 0.1497 - val_loss: 14.3024 - val_acc: 0.0627\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 6.3144 - acc: 0.1566 - val_loss: 4.1884 - val_acc: 0.1114\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 6.8074 - acc: 0.1535 - val_loss: 5.7762 - val_acc: 0.1813\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 6.1064 - acc: 0.1546 - val_loss: 5.5115 - val_acc: 0.0943\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 7.0266 - acc: 0.1570 - val_loss: 7.5021 - val_acc: 0.1383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb87bcf860>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(num_classes))\n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),\n",
    "                    callbacks=[WandbCallback(validation_data=X_test, labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-f47418669754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(Y_train, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1319 - acc: 0.3388 - val_loss: 0.1230 - val_acc: 0.3841\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1122 - acc: 0.4377 - val_loss: 0.1094 - val_acc: 0.4519\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1104 - acc: 0.4471 - val_loss: 0.1127 - val_acc: 0.4363\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1099 - acc: 0.4500 - val_loss: 0.1053 - val_acc: 0.4727\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1090 - acc: 0.4542 - val_loss: 0.1070 - val_acc: 0.4642\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1101 - acc: 0.4486 - val_loss: 0.1071 - val_acc: 0.4638\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1079 - acc: 0.4597 - val_loss: 0.1065 - val_acc: 0.4670\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1075 - acc: 0.4617 - val_loss: 0.1057 - val_acc: 0.4711\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1074 - acc: 0.4625 - val_loss: 0.1093 - val_acc: 0.4531\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1070 - acc: 0.4647 - val_loss: 0.1050 - val_acc: 0.4747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf31cbe48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='adam',  # try loss = 'mae'/'categorical_crossentropy'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),\n",
    "                    callbacks=[WandbCallback(validation_data=X_test, labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 66us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.022985279083252, 0.2205]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron - py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 5.9249 - acc: 0.6245 - val_loss: 4.1289 - val_acc: 0.7382\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 3.8017 - acc: 0.7595 - val_loss: 3.7776 - val_acc: 0.7603\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 3.5673 - acc: 0.7750 - val_loss: 3.4260 - val_acc: 0.7847\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 3.4761 - acc: 0.7814 - val_loss: 3.2526 - val_acc: 0.7953\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 3.5009 - acc: 0.7804 - val_loss: 3.5487 - val_acc: 0.7766\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 3.4160 - acc: 0.7857 - val_loss: 3.4064 - val_acc: 0.7859\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 3.3921 - acc: 0.7875 - val_loss: 3.3701 - val_acc: 0.7884\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 3.3607 - acc: 0.7896 - val_loss: 3.3823 - val_acc: 0.7877\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 3.3182 - acc: 0.7920 - val_loss: 3.2700 - val_acc: 0.7954\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 3.2940 - acc: 0.7937 - val_loss: 3.1321 - val_acc: 0.8034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf5008c18>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),\n",
    "                    callbacks=[WandbCallback(validation_data=X_test, labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1320957462310792, 0.8034]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron - normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.4366 - acc: 0.8825 - val_loss: 0.3019 - val_acc: 0.9176\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3023 - acc: 0.9161 - val_loss: 0.2919 - val_acc: 0.9195\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2887 - acc: 0.9214 - val_loss: 0.2841 - val_acc: 0.9240\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2835 - acc: 0.9231 - val_loss: 0.2805 - val_acc: 0.9266\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2812 - acc: 0.9250 - val_loss: 0.2860 - val_acc: 0.9259\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2793 - acc: 0.9269 - val_loss: 0.2847 - val_acc: 0.9264\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2779 - acc: 0.9274 - val_loss: 0.2873 - val_acc: 0.9271\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2777 - acc: 0.9277 - val_loss: 0.2905 - val_acc: 0.9270\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2777 - acc: 0.9289 - val_loss: 0.2955 - val_acc: 0.9277\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2776 - acc: 0.9297 - val_loss: 0.2937 - val_acc: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb823f47f0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# logging code\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "# normalize data\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255.\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# tune compile hyperparameters\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "# tune fit hyperparameters\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),\n",
    "                                        callbacks=[WandbCallback(validation_data=X_test, labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2937244269259274, 0.928]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# softmax: [0.3016091248065233, 0.9238]\n",
    "# adadelta: [0.2689320749565959, 0.9244]\n",
    "# Nadam: [0.27488317749053237, 0.9264]\n",
    "# RMSprop: [0.2937244269259274, 0.928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.2195 - acc: 0.9335 - val_loss: 0.1347 - val_acc: 0.9589\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0975 - acc: 0.9705 - val_loss: 0.1019 - val_acc: 0.9688\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0730 - acc: 0.9773 - val_loss: 0.0829 - val_acc: 0.9745\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0568 - acc: 0.9816 - val_loss: 0.0914 - val_acc: 0.9722\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0479 - acc: 0.9847 - val_loss: 0.0735 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0384 - acc: 0.9878 - val_loss: 0.0917 - val_acc: 0.9741\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0352 - acc: 0.9884 - val_loss: 0.0837 - val_acc: 0.9763\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0304 - acc: 0.9900 - val_loss: 0.0734 - val_acc: 0.9796\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0971 - val_acc: 0.9738\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0855 - val_acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb8a790ef0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback\n",
    "import json\n",
    "\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "\n",
    "config.hidden_nodes = 100\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255.\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
    "model.add(Dense(config.hidden_nodes, activation='selu'))\n",
    "model.add(Dense(config.hidden_nodes, activation='tanh'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "      epochs=10,\n",
    "      callbacks=[WandbCallback(validation_data=X_test, labels=labels)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout - Perceptron\n",
    "Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. Use dropout between layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3629 - acc: 0.8930 - val_loss: 0.1612 - val_acc: 0.9524\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1976 - acc: 0.9411 - val_loss: 0.1146 - val_acc: 0.9661\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1613 - acc: 0.9506 - val_loss: 0.1026 - val_acc: 0.9694\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1376 - acc: 0.9571 - val_loss: 0.0912 - val_acc: 0.9731\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1261 - acc: 0.9601 - val_loss: 0.0835 - val_acc: 0.9757\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1140 - acc: 0.9641 - val_loss: 0.0750 - val_acc: 0.9786\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1092 - acc: 0.9653 - val_loss: 0.0765 - val_acc: 0.9764\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1028 - acc: 0.9673 - val_loss: 0.0760 - val_acc: 0.9782\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0971 - acc: 0.9687 - val_loss: 0.0722 - val_acc: 0.9770\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0981 - acc: 0.9688 - val_loss: 0.0727 - val_acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb96bd97b8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "import json\n",
    "\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "\n",
    "run = wandb.init()\n",
    "config = run.config\n",
    "config.hidden_nodes = 100\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255.\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "labels = range(10)\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "        epochs=10, callbacks=[WandbCallback(validation_data=X_test, labels=labels)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
